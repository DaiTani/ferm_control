import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from datasetB import FermentationData  # 假设数据集类在 datasetB.py 中
from model import LSTMPredictor, RNNpredictor  # 假设模型类在 model.py 中
import utils

class ParameterOptimizer:
    def __init__(self, param_names, param_bounds, model, test_dataset, x_mean, x_std, y_mean, y_std):
        self.param_names = param_names
        self.param_bounds = param_bounds
        self.n_params = len(param_names)
        self.model = model
        self.test_dataset = test_dataset
        self.x_mean = x_mean
        self.x_std = x_std
        self.y_mean = y_mean
        self.y_std = y_std


    # 打印数据集完成加载后最后一行的数据
        #last_row_X = self.test_dataset.X[-1]
        #last_row_Y = self.test_dataset.Y[-1]
        #print("X 数据的最后一部分:", last_row_X[-1])
        #print("Y 数据的最后一部分:", last_row_X[-1])
    # 对最后一行数据进行逆归一化
        #last_row_X_denorm = last_row_X * self.x_std + self.x_mean
        #last_row_Y_denorm = last_row_Y * self.y_std + self.y_mean

        #print("数据集完成加载后 X 的最后一行数据: ", last_row_X_denorm)
        #print("数据集完成加载后 Y 的最后一行数据: ", last_row_Y_denorm)
    # 输出 X 和 Y 数据的最后一部分
        #print("X 数据的最后一部分:", last_row_X_denorm[-1])
        #print("Y 数据的最后一部分:", last_row_Y_denorm[-1])




        
        # 遗传算法参数
        self.pop_size = 20
        self.n_generations = 20
        self.mutation_rate = 0.1

        # 新增属性：最佳OD600
        self.best_od600 = float('-inf')		

    def optimize(self, initial_params, initial_score):
        # 初始化种群
        population = self._initialize_population(initial_params)
        self.best_params = initial_params        
        for gen in range(self.n_generations):
            # 评估适应度
            fitness = np.array([self._evaluate(ind, initial_score) for ind in population])
            
            # 选择
            selected = self._select(population, fitness)
            
            # 交叉和变异
            population = self._crossover_mutate(selected)
            #print(f"当前 population[np.argmax(fitness)] 的值: {population[np.argmax(fitness)]}")            
        return population[np.argmax(fitness)]
        
    def _initialize_population(self, base_params):
        population = []
        for _ in range(self.pop_size):
            ind = base_params.copy()
            for i in range(self.n_params):
                ind[i] += np.random.normal(0, self.param_bounds[i][1]*0.1)
                ind[i] = np.clip(ind[i], *self.param_bounds[i])
            population.append(ind)
        return np.array(population)

    def _evaluate(self, individual, baseline):
        # 更新数据集参数
        print(f"当前 individual 的值: {individual}")		
        #y = self._cumulative2snapshot(individual)  # 处理累积数据
        optimized_params_norm = self._normalize_individual(individual)

        #print(f"归一化 individual111 的值: {optimized_params_norm}")
        last_row_X_denorm1 = optimized_params_norm * self.x_std + self.x_mean		
        #print(f"逆归一化 last_row_X_denorm1 的值: {last_row_X_denorm1}")
		
        last_row_X = self.test_dataset.X[-1]
        last_row_Y = self.test_dataset.Y[-1]
        #print("X 数据的最后一部分:", last_row_X)
        #print("Y 数据的最后一部分:", last_row_Y)		

    # 对最后一行数据进行逆归一化
        last_row_X_denorm = last_row_X * self.x_std + self.x_mean
        last_row_Y_denorm = last_row_Y * self.y_std + self.y_mean

        #print("数据集完成加载后 X 的最后一行数据: ", last_row_X_denorm)
        #print("数据集完成加载后 Y 的最后一行数据: ", last_row_Y_denorm)
    # 输出 X 和 Y 数据的最后一部分
        #print("X 数据的最后一部分:", last_row_X_denorm[-1])
        #print("Y 数据的最后一部分:", last_row_Y_denorm[-1])


        #print("self.test_dataset.X[-1][-1]:", self.test_dataset.X[-1][-1])		
        self.test_dataset.X[-1][-1] = optimized_params_norm
        #print("赋值后的self.test_dataset.X[-1][-1]:", self.test_dataset.X[-1][-1])			
		
        self.test_dataset.X = self.test_dataset.X * self.x_std + self.x_mean
        self.test_dataset.Y = self.test_dataset.Y * self.y_std + self.y_mean		
		
		
		
		
        self.test_dataset.update_windows()
        #last_row_X_denorm1 = optimized_params_norm * self.x_std + self.x_mean
        #print(f"当前 individua222 的值: {optimized_params_norm}")
        #print(f"当前 last_row_X_denorm222 的值: {last_row_X_denorm1}")		
    # 打印数据集完成加载后最后一行的数据
        last_row_X = self.test_dataset.X[-1]
        last_row_Y = self.test_dataset.Y[-1]
        #print("X 数据的最后一部分up:", last_row_X[-1])
        #print("Y 数据的最后一部分up:", last_row_Y[-1])
    # 对最后一行数据进行逆归一化
        last_row_X_denorm = last_row_X * self.x_std + self.x_mean
        last_row_Y_denorm = last_row_Y * self.y_std + self.y_mean
        #print("self.x_std:", self.x_std)
        #print("self.x_mean:", self.x_mean)
        #print("Y 数据的最后一部分:", last_row_X[-1])
        #print("数据集完成加载后 X 的最后一行数据: ", last_row_X_denorm)
        #print("数据集完成加载后 Y 的最后一行数据: ", last_row_Y_denorm)
    # 输出 X 和 Y 数据的最后一部分
        #print("X 数据的你归一化最后一部分:", last_row_X_denorm[-1])
        #print("Y 数据的你归一化最后一部分:", last_row_Y_denorm[-1])
		
        # 重新初始化DataLoader
        test_loader = DataLoader(
            dataset=self.test_dataset, batch_size=1, num_workers=0, shuffle=False
        )

        # 调用 test 函数进行预测
        err, preds, labels = self.test(0, self.model, test_loader)
        #print("self.y_std:", self.y_std)
        #print("self.y_mean:", self.y_mean)
        preds_denorm = preds * self.y_std + self.y_mean
        current_od600 = preds_denorm[-1]
        preds_denormV = last_row_X * self.x_std + self.x_mean

        # 更新最佳OD600
        if current_od600 > self.best_od600:
            self.best_od600 = current_od600
            self.best_params = preds_denormV[-1]
        print(f"当前预测OD600: {current_od600:.4f} | 历史最佳OD600: {self.best_od600:.4f}")
        print(f"当前 best_params 的值: {self.best_params}")	        
        # 设置数据集

        return current_od600

    def _select(self, population, fitness):
        if len(population) <= 2:
            return population
        return population[np.argsort(fitness)[-int(self.pop_size*0.5):]]

    def _crossover_mutate(self, selected):
        new_pop = []
        while len(new_pop) < self.pop_size:
            indices = np.random.permutation(len(selected))[:2]  # 随机选择两个个体的索引
            parents = selected[indices]
            child = (parents[0] + parents[1])/2
            for i in range(self.n_params):
                if np.random.rand() < self.mutation_rate:
                    child[i] += np.random.normal(0, self.param_bounds[i][1]*0.2)
                    child[i] = np.clip(child[i], *self.param_bounds[i])
            new_pop.append(child)
        return np.array(new_pop)

    def test(self, epoch, model, testloader):
        model.eval()
        loss = 0
        err = 0
        iter = 0
        h = model.init_hidden(1)  # batch_size 为 1
        preds = np.zeros(len(self.test_dataset) + self.test_dataset.ws - 1)
        labels = np.zeros(len(self.test_dataset) + self.test_dataset.ws - 1)
        n_overlap = np.zeros(len(self.test_dataset) + self.test_dataset.ws - 1)

        N = 10
        with torch.no_grad():
            for batch_idx, (input, label) in enumerate(testloader):
                iter += 1
                batch_size = input.size(0)
                h = model.init_hidden(batch_size)
                h = tuple([e.data for e in h])
                input, label = input.cuda(), label.cuda()
                output, h = model(input.float(), h)
                y = output.view(-1).cpu().numpy()
                y_padded = np.pad(y, (N // 2, N - 1 - N // 2), mode="edge")
                y_smooth = np.convolve(y_padded, np.ones((N,)) / N, mode="valid")
                preds[batch_idx : (batch_idx + self.test_dataset.ws)] += y_smooth
                labels[batch_idx : (batch_idx + self.test_dataset.ws)] += label.view(-1).cpu().numpy()
                n_overlap[batch_idx : (batch_idx + self.test_dataset.ws)] += 1.0
                loss += self.mse(output, label.float())
                err += torch.sqrt(self.mse(output, label.float())).item()

        loss = loss / len(self.test_dataset)
        err = err / len(self.test_dataset)
        preds /= n_overlap
        labels /= n_overlap
        return err, preds, labels

    def mse(self, output, target):
        return torch.mean((output - target) ** 2)
    def _normalize_individual(self, individual):
        """
        归一化 individual 数据
        """
        return (individual - self.x_mean) / self.x_std	
    def _cumulative2snapshot(self, data):
    # Trasform cumulative data to snapshot data

        tmp_data = np.insert(data, 0, data[0])[:-1]

        return data - tmp_data