datasetC.py
###########################
from __future__ import print_function
import os
from os.path import join
import numpy as np
import sys
import utils
import torch
from torch.utils.data import Dataset
import glob
import pdb
import pandas as pd


class FermentationData(Dataset):
    def __init__(
        self, work_dir="./Data", train_mode=True, y_var=["od_600"], ws=20, stride=5, timestamp=None, y_mean=None, y_std=None
    ):
        self.work_dir = work_dir
        self.train = train_mode
        self.timestamp = timestamp  # 新增：支持时间戳筛选
        self.y_mean = y_mean
        self.y_std = y_std
        print("yyyy: ", y_mean)
        print("yyyy: ", y_std)	
        print("Loading dataset...")  # 添加打印语句
        # lists of number of fermentations for training and testing
        # Data
        self.train_fermentations = [
            8,  # 0.540000
            11,  # 3.670000
            12,  # 3.840000
            #### 14,  # 4.500000
            #16,  # 2.050000
            ### 17,  # 17.000000
            ### 19,  # 14.500000
            ### 20,  # 14.800000
            #22,  # 0.500000
            #23,  # 0.570000
            #24,  # 0.530000
            #25,  # 0.554000
            #26,  # 0.532000
            #27,  # 0.598000
            # 28,  # 0.674000
        ]
        self.test_fermentations = [28]

        # variables with cumulative values
        self.cumulative_var = [
            #"dm_o2",
            #"dm_air",
            #"dm_spump1",
            #"dm_spump2",
            #"dm_spump3",
            #"dm_spump4",
        ]
        # variables with binary values
        self.binary_var = ["induction"]

        # input variables
        self.x_var = [
            "dm_air",
            "m_ls_opt_do",
            "m_ph",
            "m_stirrer",
            "m_temp",
            "dm_o2",
            "dm_spump1",
            "dm_spump2",
            "dm_spump3",
            "dm_spump4",
            "induction",
        ]
        # output variable
        self.y_var = y_var

        # Using fermentation 16 for computing normalisation parameters
        self.fermentation_norm_number = 22  # 16
        self.X_norm, self.Y_norm = self.load_data(
            fermentation_number=self.fermentation_norm_number
        )
        self.X_norm = self.X_norm[0]
        self.X_norm = self.cumulative2snapshot(self.X_norm)
        self.Y_norm = self.Y_norm[0]
        self.Y_norm = self.cumulative2snapshot(self.Y_norm)  # 处理Y的累积数据

        # Loading data
        self.X, self.Y = self.load_data()

        # Initialize normalization parameters for labels
        #self.y_mean = None
        #self.y_std = None

        if self.train:
            self.ws, self.stride = (ws, stride)
        else:
            self.ws, self.stride = (ws, 1)  # Stride for test is set to 1

        # Preprocessing data
        self.X = self.preprocess_data(
            self.X, norm_mode="z-score", ws=self.ws, stride=self.stride
        )
        self.Y = self.preprocess_labels(
            self.Y, norm_mode="z-score", ws=self.ws, stride=self.stride
        )

        # Shuffling for training
        if self.train:
            np.random.seed(1234)
            idx = np.random.permutation(len(self.X))

            self.X = self.X[idx]
            self.Y = self.Y[idx]

    def load_data(self, fermentation_number=None):
        # Load data for train/test fermentations
        X = []
        Y = []

        # Loading single fermentation data
        if fermentation_number is not None:
            data = utils.load_data(
                work_dir=self.work_dir,
                fermentation_number=fermentation_number,
                data_file="data.xlsx",
                x_cols=self.x_var,
                y_cols=self.y_var,
            )
            X.append(data[0])
            Y.append(data[1])

            return np.array(X), np.array(Y)

        # Loading train/test fermentations data
        if self.train:
            for fn in self.train_fermentations:
                data = utils.load_data(
                    work_dir=self.work_dir,
                    fermentation_number=fn,
                    data_file="data.xlsx",
                    x_cols=self.x_var,
                    y_cols=self.y_var,
                )
                X.append(data[0])
                Y.append(data[1])
        else:
            for fn in self.test_fermentations:
                data = utils.load_data(
                    work_dir=self.work_dir,
                    fermentation_number=fn,
                    data_file="data.xlsx",
                    x_cols=self.x_var,
                    y_cols=self.y_var,
                )
                X.append(data[0])
                Y.append(data[1])

        # 如果指定了时间戳，筛选对应数据
        if self.timestamp is not None:
            X_filtered = []
            Y_filtered = []
            for x, y in zip(X, Y):
                df = pd.DataFrame(x, columns=self.x_var)
                df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce', dayfirst=True)
                df_filtered = df[df['Timestamp'] == self.timestamp]
                if not df_filtered.empty:
                    X_filtered.append(df_filtered[self.x_var].values)
                    Y_filtered.append(y[df.index.isin(df_filtered.index)])
            X = X_filtered
            Y = Y_filtered

        return np.array(X), np.array(Y)

    def preprocess_data(self, X, norm_mode="z-score", ws=20, stride=10):
        # Preprocess data
        mean, std = utils.get_norm_param(X=self.X_norm, x_cols=self.x_var)

        processed_X = []
        for i, x in enumerate(X):
            x = self.cumulative2snapshot(x)
            x = self.normalise(x, mean, std, norm_mode)
            x = self.data2sequences(x, ws, stride)

            processed_X.append(x)

        processed_X = np.concatenate(processed_X, axis=0)

        return processed_X

    def preprocess_labels(self, Y, norm_mode="z-score", ws=20, stride=10):
        # Preprocess labels
        mean, std = utils.get_norm_param(X=self.Y_norm, x_cols=self.y_var)  # 确保参数名称一致

        processed_Y = []
        for y in Y:
            y = self.cumulative2snapshot(y)  # 处理累积数据
            y = self.normalise(y, mean, std, norm_mode)  # 归一化
            y = self.data2sequences(y, ws, stride)  # 转换为序列

            processed_Y.append(y)

        return np.concatenate(processed_Y, axis=0)

    def cumulative2snapshot(self, X):
        # Trasform cumulative data to snapshot data
        X = np.copy(X)

        for cv in self.cumulative_var:
            if cv in self.x_var:
                idx = self.x_var.index(cv)
            elif cv in self.y_var:
                idx = self.y_var.index(cv)

            X[:, idx] = utils.cumulative2snapshot(X[:, idx])

        return X

    def normalise(self, X, mean, std, mode="z-score"):
        # Normalise data
        binary_var_idx = []
        for bv in self.binary_var:
            if bv in self.x_var:
                idx = self.x_var.index(bv)
                if idx < X.shape[1]:
                    binary_var_idx.append(idx)
            elif bv in self.y_var:
                idx = self.y_var.index(bv)
                if idx < X.shape[1]:
                    binary_var_idx.append(idx)

        return utils.normalise(
            X, mean=mean, std=std, mode=mode, binary_var=binary_var_idx
        )

    def data2sequences(self, X, ws=20, stride=10):
        # Transform data to sequences with default sliding window 20 and stride 10
        return utils.data2sequences(X, ws, stride)

    def polynomial_interpolation(self, data):
        # Compute polynomial interpolation
        data = data[:, 0]

        if np.isnan(data[0]):
            data[0] = 0

        return utils.polynomial_interpolation(data).reshape(-1, 1)

    def linear_local_interpolation(self, data):
        # Compute linear local interpolation
        data = data[:, 0]

        if np.isnan(data[0]):
            data[0] = 0

        return utils.linear_local_interpolation(data).reshape(-1, 1)

    def mix_interpolation(self, data):
        # Compute linear local interpolation
        data = data[:, 0]

        a, b = (0.5, 0.5)

        if np.isnan(data[0]):
            data[0] = 0

        return utils.mix_interpolation(data).reshape(-1, 1)

    def __getitem__(self, index):
        x = self.X[index]
        y = self.Y[index]

        x = torch.tensor(x)
        y = torch.tensor(y)

        return [x, y]

    def __len__(self):
        return self.X.shape[0]

    def get_num_features(self):
        return self.X.shape[-1]
		
    def update_windows(self):
        # 更新滑动窗口
        self.X = self.preprocess_data(
            self.X, norm_mode="z-score", ws=self.ws, stride=self.stride
        )
        self.Y = self.preprocess_labels(
            self.Y, norm_mode="z-score", ws=self.ws, stride=self.stride
        )		

###########################


Ga.py
###########################
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from datasetB import FermentationData  # 假设数据集类在 datasetB.py 中
from model import LSTMPredictor, RNNpredictor  # 假设模型类在 model.py 中
import utils

class ParameterOptimizer:
    def __init__(self, param_names, param_bounds, model, test_dataset, x_mean, x_std, y_mean, y_std):
        self.param_names = param_names
        self.param_bounds = param_bounds
        self.n_params = len(param_names)
        self.model = model
        self.test_dataset = test_dataset
        self.x_mean = x_mean
        self.x_std = x_std
        self.y_mean = y_mean
        self.y_std = y_std


    # 打印数据集完成加载后最后一行的数据
        #last_row_X = self.test_dataset.X[-1]
        #last_row_Y = self.test_dataset.Y[-1]
        #print("X 数据的最后一部分:", last_row_X[-1])
        #print("Y 数据的最后一部分:", last_row_X[-1])
    # 对最后一行数据进行逆归一化
        #last_row_X_denorm = last_row_X * self.x_std + self.x_mean
        #last_row_Y_denorm = last_row_Y * self.y_std + self.y_mean

        #print("数据集完成加载后 X 的最后一行数据: ", last_row_X_denorm)
        #print("数据集完成加载后 Y 的最后一行数据: ", last_row_Y_denorm)
    # 输出 X 和 Y 数据的最后一部分
        #print("X 数据的最后一部分:", last_row_X_denorm[-1])
        #print("Y 数据的最后一部分:", last_row_Y_denorm[-1])




        
        # 遗传算法参数
        self.pop_size = 20
        self.n_generations = 20
        self.mutation_rate = 0.1

        # 新增属性：最佳OD600
        self.best_od600 = float('-inf')		

    def optimize(self, initial_params, initial_score):
        # 初始化种群
        population = self._initialize_population(initial_params)
        self.best_params = initial_params        
        for gen in range(self.n_generations):
            # 评估适应度
            fitness = np.array([self._evaluate(ind, initial_score) for ind in population])
            
            # 选择
            selected = self._select(population, fitness)
            
            # 交叉和变异
            population = self._crossover_mutate(selected)
            #print(f"当前 population[np.argmax(fitness)] 的值: {population[np.argmax(fitness)]}")            
        return population[np.argmax(fitness)]
        
    def _initialize_population(self, base_params):
        population = []
        for _ in range(self.pop_size):
            ind = base_params.copy()
            for i in range(self.n_params):
                ind[i] += np.random.normal(0, self.param_bounds[i][1]*0.1)
                ind[i] = np.clip(ind[i], *self.param_bounds[i])
            population.append(ind)
        return np.array(population)

    def _evaluate(self, individual, baseline):
        # 更新数据集参数
        print(f"当前 individual 的值: {individual}")		
        #y = self._cumulative2snapshot(individual)  # 处理累积数据
        optimized_params_norm = self._normalize_individual(individual)

        #print(f"归一化 individual111 的值: {optimized_params_norm}")
        last_row_X_denorm1 = optimized_params_norm * self.x_std + self.x_mean		
        #print(f"逆归一化 last_row_X_denorm1 的值: {last_row_X_denorm1}")
		
        last_row_X = self.test_dataset.X[-1]
        last_row_Y = self.test_dataset.Y[-1]
        #print("X 数据的最后一部分:", last_row_X)
        #print("Y 数据的最后一部分:", last_row_Y)		

    # 对最后一行数据进行逆归一化
        last_row_X_denorm = last_row_X * self.x_std + self.x_mean
        last_row_Y_denorm = last_row_Y * self.y_std + self.y_mean

        #print("数据集完成加载后 X 的最后一行数据: ", last_row_X_denorm)
        #print("数据集完成加载后 Y 的最后一行数据: ", last_row_Y_denorm)
    # 输出 X 和 Y 数据的最后一部分
        #print("X 数据的最后一部分:", last_row_X_denorm[-1])
        #print("Y 数据的最后一部分:", last_row_Y_denorm[-1])


        #print("self.test_dataset.X[-1][-1]:", self.test_dataset.X[-1][-1])		
        self.test_dataset.X[-1][-1] = optimized_params_norm
        #print("赋值后的self.test_dataset.X[-1][-1]:", self.test_dataset.X[-1][-1])			
		
        self.test_dataset.X = self.test_dataset.X * self.x_std + self.x_mean
        self.test_dataset.Y = self.test_dataset.Y * self.y_std + self.y_mean		
		
		
		
		
        self.test_dataset.update_windows()
        #last_row_X_denorm1 = optimized_params_norm * self.x_std + self.x_mean
        #print(f"当前 individua222 的值: {optimized_params_norm}")
        #print(f"当前 last_row_X_denorm222 的值: {last_row_X_denorm1}")		
    # 打印数据集完成加载后最后一行的数据
        last_row_X = self.test_dataset.X[-1]
        last_row_Y = self.test_dataset.Y[-1]
        #print("X 数据的最后一部分up:", last_row_X[-1])
        #print("Y 数据的最后一部分up:", last_row_Y[-1])
    # 对最后一行数据进行逆归一化
        last_row_X_denorm = last_row_X * self.x_std + self.x_mean
        last_row_Y_denorm = last_row_Y * self.y_std + self.y_mean
        #print("self.x_std:", self.x_std)
        #print("self.x_mean:", self.x_mean)
        #print("Y 数据的最后一部分:", last_row_X[-1])
        #print("数据集完成加载后 X 的最后一行数据: ", last_row_X_denorm)
        #print("数据集完成加载后 Y 的最后一行数据: ", last_row_Y_denorm)
    # 输出 X 和 Y 数据的最后一部分
        #print("X 数据的你归一化最后一部分:", last_row_X_denorm[-1])
        #print("Y 数据的你归一化最后一部分:", last_row_Y_denorm[-1])
		
        # 重新初始化DataLoader
        test_loader = DataLoader(
            dataset=self.test_dataset, batch_size=1, num_workers=0, shuffle=False
        )

        # 调用 test 函数进行预测
        err, preds, labels = self.test(0, self.model, test_loader)
        #print("self.y_std:", self.y_std)
        #print("self.y_mean:", self.y_mean)
        preds_denorm = preds * self.y_std + self.y_mean
        current_od600 = preds_denorm[-1]
        preds_denormV = last_row_X * self.x_std + self.x_mean

        # 更新最佳OD600
        if current_od600 > self.best_od600:
            self.best_od600 = current_od600
            self.best_params = preds_denormV[-1]
        print(f"当前预测OD600: {current_od600:.4f} | 历史最佳OD600: {self.best_od600:.4f}")
        print(f"当前 best_params 的值: {self.best_params}")	        
        # 设置数据集

        return current_od600

    def _select(self, population, fitness):
        if len(population) <= 2:
            return population
        return population[np.argsort(fitness)[-int(self.pop_size*0.5):]]

    def _crossover_mutate(self, selected):
        new_pop = []
        while len(new_pop) < self.pop_size:
            indices = np.random.permutation(len(selected))[:2]  # 随机选择两个个体的索引
            parents = selected[indices]
            child = (parents[0] + parents[1])/2
            for i in range(self.n_params):
                if np.random.rand() < self.mutation_rate:
                    child[i] += np.random.normal(0, self.param_bounds[i][1]*0.2)
                    child[i] = np.clip(child[i], *self.param_bounds[i])
            new_pop.append(child)
        return np.array(new_pop)

    def test(self, epoch, model, testloader):
        model.eval()
        loss = 0
        err = 0
        iter = 0
        h = model.init_hidden(1)  # batch_size 为 1
        preds = np.zeros(len(self.test_dataset) + self.test_dataset.ws - 1)
        labels = np.zeros(len(self.test_dataset) + self.test_dataset.ws - 1)
        n_overlap = np.zeros(len(self.test_dataset) + self.test_dataset.ws - 1)

        N = 10
        with torch.no_grad():
            for batch_idx, (input, label) in enumerate(testloader):
                iter += 1
                batch_size = input.size(0)
                h = model.init_hidden(batch_size)
                h = tuple([e.data for e in h])
                input, label = input.cuda(), label.cuda()
                output, h = model(input.float(), h)
                y = output.view(-1).cpu().numpy()
                y_padded = np.pad(y, (N // 2, N - 1 - N // 2), mode="edge")
                y_smooth = np.convolve(y_padded, np.ones((N,)) / N, mode="valid")
                preds[batch_idx : (batch_idx + self.test_dataset.ws)] += y_smooth
                labels[batch_idx : (batch_idx + self.test_dataset.ws)] += label.view(-1).cpu().numpy()
                n_overlap[batch_idx : (batch_idx + self.test_dataset.ws)] += 1.0
                loss += self.mse(output, label.float())
                err += torch.sqrt(self.mse(output, label.float())).item()

        loss = loss / len(self.test_dataset)
        err = err / len(self.test_dataset)
        preds /= n_overlap
        labels /= n_overlap
        return err, preds, labels

    def mse(self, output, target):
        return torch.mean((output - target) ** 2)
    def _normalize_individual(self, individual):
        """
        归一化 individual 数据
        """
        return (individual - self.x_mean) / self.x_std	
    def _cumulative2snapshot(self, data):
    # Trasform cumulative data to snapshot data

        tmp_data = np.insert(data, 0, data[0])[:-1]

        return data - tmp_data
#######################

test2.py
########################
import sys
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torch.backends.cudnn as cudnn
import os
import argparse
import numpy as np
from datasetC import *
import pdb
import warnings
from model import *
import random
import utils
import math
import pandas as pd
import matplotlib.pyplot as plt
import json
from Ga import ParameterOptimizer  # 导入优化器类


def main():
    parser = argparse.ArgumentParser(description="PyTorch CIFAR Training")
    parser.add_argument("--batch_size", default=256, type=int, help="test batchsize")
    parser.add_argument("--hidden_dim", default=16, type=int)
    parser.add_argument("--num_layers", default=2, type=int)
    parser.add_argument("--seed", default=123)
    parser.add_argument("--gpuid", default=0, type=int)
    parser.add_argument("--weights", type=str, default="")
    parser.add_argument("--dataset", type=str, default="")
    parser.add_argument("--model", default="lstm", type=str)
    parser.add_argument("--pred_steps", default=1, type=int, help="Number of prediction steps")

    args = parser.parse_args()
    warnings.filterwarnings("ignore")

    torch.cuda.set_device(args.gpuid)
    random.seed(args.seed)
    torch.manual_seed(args.seed)
    torch.cuda.manual_seed_all(args.seed)

    # Predict with overlapped sequences
    def test(epoch, model, testloader):
        model.eval()

        loss = 0
        err = 0

        iter = 0

        # Initialise model hidden state
        h = model.init_hidden(args.batch_size)

        # Initialise vectors to store predictions, labels
        preds = np.zeros(len(test_dataset) + test_dataset.ws - 1)
        labels = np.zeros(len(test_dataset) + test_dataset.ws - 1)
        n_overlap = np.zeros(len(test_dataset) + test_dataset.ws - 1)

        N = 10
        with torch.no_grad():
            for batch_idx, (input, label) in enumerate(testloader):
                iter += 1

                batch_size = input.size(0)

                h = model.init_hidden(batch_size)
                h = tuple([e.data for e in h])

                input, label = input.cuda(), label.cuda()

                output, h = model(input.float(), h)
                #print("output shape:", output.shape)
                #print("output values:", output)
				
                y = output.view(-1).cpu().numpy()
                y_padded = np.pad(y, (N // 2, N - 1 - N // 2), mode="edge")
                y_smooth = np.convolve(y_padded, np.ones((N,)) / N, mode="valid")
                #print("y_smooth values:", y_smooth)
                # Store predictions and labels summing over the overlapping
                preds[
                    batch_idx: (batch_idx + test_dataset.ws)
                ] += y_smooth
                labels[batch_idx: (batch_idx + test_dataset.ws)] += (
                    label.view(-1).cpu().numpy()
                )
                n_overlap[batch_idx: (batch_idx + test_dataset.ws)] += 1.0

                loss += nn.MSELoss()(output, label.float())
                err += torch.sqrt(nn.MSELoss()(output, label.float())).item()

        loss = loss / len(test_dataset)
        err = err / len(test_dataset)

        # Compute the average dividing for the number of overlaps
        preds /= n_overlap
        labels /= n_overlap

        return err, preds, labels

    def _normalize_individual(optimized_params):
        """
        归一化 individual 数据
        """
        return (optimized_params - x_mean) / x_std

    # 加载归一化参数
    norm_file_path = os.path.join(args.dataset, "norm_file.json")
    with open(norm_file_path, 'r') as f:
        norm_data = json.load(f)
    y_mean = norm_data['y_mean']
    y_std = norm_data['y_std']

    # 设置数据集
    test_dataset = FermentationData(
        work_dir=args.dataset, train_mode=False, y_var=["od_600"], y_mean=y_mean, y_std=y_std
    )

    # 获取 X 的归一化参数
    x_mean, x_std = utils.get_norm_param(X=test_dataset.X_norm, x_cols=test_dataset.x_var)

    # 打印数据集完成加载后最后一行的数据
    last_row_X = test_dataset.X[-1]
    last_row_Y = test_dataset.Y[-1]

    # 对最后一行数据进行逆归一化
    last_row_X_denorm = last_row_X * x_std + x_mean
    last_row_Y_denorm = last_row_Y * y_std + y_mean

    print("数据集完成加载后 X 的最后一行数据: ", last_row_X_denorm)
    print("数据集完成加载后 Y 的最后一行数据: ", last_row_Y_denorm)
    # 输出 X 和 Y 数据的最后一部分
    print("X 数据的最后一部分:", last_row_X_denorm[-1])
    print("Y 数据的最后一部分:", last_row_Y_denorm[-1])

    # 设置 DataLoader
    test_loader = torch.utils.data.DataLoader(
        dataset=test_dataset, batch_size=1, num_workers=2, shuffle=False
    )

    # 设置模型
    if args.model == "lstm":
        model = LSTMPredictor(
            input_dim=test_dataset.get_num_features(),
            hidden_dim=args.hidden_dim,
            output_dim=1,
            n_layers=args.num_layers,
        )
    elif args.model == "rnn":
        model = RNNpredictor(
            input_dim=test_dataset.get_num_features(),
            hidden_dim=args.hidden_dim,
            output_dim=1,
            n_layers=args.num_layers,
        )

    model.cuda()

    # 加载模型权重
    weights = (
        os.path.join("model_weights", "od600_prediction", args.model, "weights_best.tar")
        if args.weights == ""
        else args.weights
    )
    model = utils.load_weights(model, weights)

    mse = nn.MSELoss()

    # 第一轮测试
    print("\nInitial Testing")
    err, preds, labels = test(0, model, test_loader)
    preds_denorm = preds * y_std + y_mean
    initial_od600 = preds_denorm[-1]
    print(f"Initial OD600: {initial_od600}")

	

	
    # 参数优化
    param_names = test_dataset.x_var  # 使用所有输入特征作为待优化参数
    initial_state = test_dataset.X[-1][-1].copy() * x_std + x_mean
    initial_params = initial_state[:11].copy()
    print(f"Initial params: {initial_params}")	
    epsilon = 1e-6

    # 打印 initial_params 的形状和内容，用于调试
    #print("initial_params shape:", initial_params.shape)
    #print("initial_params content:", initial_params)	
	
    # 调整参数优化范围（避免诱导剂浓度突变）
    param_bounds = [
        (max(epsilon, initial_params[0] - 0), initial_params[0] + initial_params[0]*0.1),  # 假设 initial_params[0] 是数组，取第一个元素
        (max(epsilon, initial_params[1] - initial_params[1]*0.1), initial_params[1] + initial_params[1]*0.1),  # 假设 initial_params[1] 是数组，取第一个元素
        (max(3.0, initial_params[2] - initial_params[2]*0.1), min(8.0, initial_params[2] + initial_params[2]*0.1)),  # 假设 initial_params[2] 是数组，取第一个元素
        (max(epsilon, initial_params[3] - initial_params[3]*0.1), initial_params[3] + initial_params[3]*0.1),  # 假设 initial_params[3] 是数组，取第一个元素
        (initial_params[4] - initial_params[4]*0.1, initial_params[4] + initial_params[4]*0.1),  # 假设 initial_params[4] 是数组，取第一个元素
        (max(epsilon, initial_params[5] - 0), initial_params[5] + initial_params[5]*0.1),  # 假设 initial_params[5] 是数组，取第一个元素
        (max(epsilon, initial_params[6] - 0), initial_params[6] + initial_params[6]*0.1),  # 假设 initial_params[6] 是数组，取第一个元素
        (max(epsilon, initial_params[7] - 0), initial_params[7] + initial_params[7]*0.1),  # 假设 initial_params[7] 是数组，取第一个元素
        (max(epsilon, initial_params[8] - 0), initial_params[8] + initial_params[8]*0.1),  # 假设 initial_params[8] 是数组，取第一个元素
        (max(epsilon, initial_params[9] - 0), initial_params[9] + initial_params[9]*0.1),  # 假设 initial_params[9] 是数组，取第一个元素
        (max(0.1, initial_params[10] - initial_params[10]*0.1), min(0.9, initial_params[10] + initial_params[5]*0.1))  # 假设 initial_params[10] 是数组，取第一个元素
    ]	
	
    optimizer = ParameterOptimizer(param_names, param_bounds, model, test_dataset, x_mean, x_std, y_mean, y_std)

    best_params = test_dataset.X[-1][-1] * x_std + x_mean  # 逆归一化得到初始参数值
    best_od600 = initial_od600

    initial_params = test_dataset.X[-1][-1] * x_std + x_mean

    optimized_params = optimizer.optimize(initial_params, best_od600)


        # 更新数据集参数
    print(f"当前 individual 的值: {optimized_params}")		
        #y = self._cumulative2snapshot(optimized_params)  # 处理累积数据
    optimized_params_norm = _normalize_individual(optimized_params)

    #print(f"归一化 individual111 的值: {optimized_params_norm}")
    last_row_X_denorm1 = optimized_params_norm * x_std + x_mean		
    #print(f"逆归一化 last_row_X_denorm1 的值: {last_row_X_denorm1}")
		
    last_row_X = test_dataset.X[-1]
    last_row_Y = test_dataset.Y[-1]
        #print("X 数据的最后一部分:", last_row_X)
        #print("Y 数据的最后一部分:", last_row_Y)		

    # 对最后一行数据进行逆归一化
    last_row_X_denorm = last_row_X * x_std + x_mean
    last_row_Y_denorm = last_row_Y * y_std + y_mean

        #print("数据集完成加载后 X 的最后一行数据: ", last_row_X_denorm)
        #print("数据集完成加载后 Y 的最后一行数据: ", last_row_Y_denorm)
    # 输出 X 和 Y 数据的最后一部分
        #print("X 数据的最后一部分:", last_row_X_denorm[-1])
        #print("Y 数据的最后一部分:", last_row_Y_denorm[-1])










    
    optimized_params_norm = (optimized_params - x_mean) / x_std
    test_dataset.X[-1][-1] = optimized_params_norm
    #test_dataset.update_windows()
    test_loader = torch.utils.data.DataLoader(
        dataset=test_dataset, batch_size=1, num_workers=2, shuffle=False
    )
    err, preds, labels = test(0, model, test_loader)
    preds_denorm = preds * y_std + y_mean
    current_od600 = preds_denorm[-1]

    if current_od600 > best_od600:
        best_od600 = current_od600
        best_params = optimized_params

    print("\nOptimization Results:")
    print(f"Initial OD600: {initial_od600}, Initial parameters: {initial_params}")
    print(f"Best OD600: {best_od600}, Best parameters: {best_params}")

    # 逆归一化预测结果和标签
    preds_denorm = preds * y_std + y_mean
    labels_denorm = labels * y_std + y_mean

    preds_denorm = preds_denorm.reshape(-1, 1)
    labels_denorm = labels_denorm.reshape(-1, 1)

    preds_denorm = preds_denorm[50:]
    labels_denorm = labels_denorm[50:]

    mse = np.square(np.subtract(preds_denorm, labels_denorm)).mean()
    rmse = math.sqrt(mse)

    # Relative Error on Final Yield
    refy = abs(preds_denorm[-1] - labels_denorm[-1]) / labels_denorm[-1] * 100

    # 读取 data.xlsx 文件的第一列数据
    data_path = os.path.join(args.dataset, "28", "data.xlsx")
    df = pd.read_excel(data_path)
    first_column = df.iloc[:, 0].values
    first_column = first_column[50:]  # 与 preds 和 labels 对齐

    # 将 rmse 和 refy 扩展为与 first_column 长度相同的数组
    rmse_array = np.full_like(first_column, rmse)
    refy_array = np.full_like(first_column, refy)

    # 将第一列数据添加到 results.npz 的最左侧
    timestamp_data = np.column_stack((first_column, preds_denorm, labels_denorm, rmse_array, refy_array))

    # 保存到 results.npz
    np.savez(
        weights.split("/weights")[0] + "/results.npz",
        Timestamp=timestamp_data,
        preds=preds_denorm,
        labels=labels_denorm,
        rmse=rmse,
        refy=refy,
    )
    print("Saved: ", weights.split("/weights")[0] + "/results.npz")

    # 绘制曲线
    utils.plot_od600_curve(
        preds_denorm, labels_denorm, weights[:-17], rmse, refy
    )

    print("\nRMSE Error OD600: ", rmse)
    print(
        "\nREFY: %.2f%%" % (refy), "[absolute error: %.2f]" % (abs(preds_denorm[-1] - labels_denorm[-1]))
    )

    # 绘制多步预测曲线
    plt.figure(figsize=(10, 6))
    plt.title(f"Multi-step Prediction (Prediction Steps: {args.pred_steps})")
    plt.plot(labels_denorm, label="True Values", color="black", linewidth=2)
    for step in range(args.pred_steps):
        plt.plot(preds_denorm[:, step], label=f"Predicted Step {step + 1}")
    plt.legend()
    plt.xlabel("Time Steps")
    plt.ylabel("OD600")
    plt.savefig(weights.split("/weights")[0] + "/multi_step_prediction.png")
    plt.show()


if __name__ == '__main__':
    main()

##################################



